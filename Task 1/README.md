# CarbonMarketsHQ_Assignment 1

I have used two approaches in this task.

# 1- CarbonMarketsHQ_Assignment 1 File

Here the workflow is as follows:

1- Importing nexessary libraires
2- Reading the first file in Dataframe
3- Handling data inconsistencies in file 1
4- Saving the cleaned dataframe as a new file.
5- Repeating same process with file 2.
6- Mapping both the dataframes and creating a new excel file which consist of the required data.
7- Performing the analysis on the newly created file.
8- (Bonus) Creating a interface to get data from file.

Files used and created can be found here: 
https://drive.google.com/drive/folders/1TKkcxh-U6riRlIrM7T3SezxgOTVutWEp?usp=sharing

Files used here are:
1.xlsx
2.xlsx

Files created are:
cleaned_data1.xlsx
cleaned_data2.xlsx
unified_data.xlsx


# 2- Task1 File

The end result is same as the above file but the workflow is slight different.

1- Importing Necessary libraries
2- Loading the excel files and standardizing the column names of both files.
3- Mapping each dataframe 
4- Creating a new excel file consisting of required data.
5- Cleaning the data in new file and handling incosnsistencies.
6- Grouping the data based on project type.
7- Analyzing data and creating some visual representation of analysis.
8- (Bonus) Implementing query feature


Files used and created can be found here: 
https://drive.google.com/drive/folders/1TKkcxh-U6riRlIrM7T3SezxgOTVutWEp?usp=sharing

Files used here are:
1.xlsx
2.xlsx

Files created here are:
raw.xlsx




# Challanges Faced

The biggest challange here was to clean the real world data provided.
I implemented two different methods(mentioned above) to tackle this challange.
